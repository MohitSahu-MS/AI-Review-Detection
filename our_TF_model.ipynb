{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dsDTHm3XSHQ4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NKjn4ztFTyj9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
        "from torch import nn\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2TbA2afT4KX"
      },
      "source": [
        "# TF Model Neural Network:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aKfrDMrPTzeO"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layer_2 = nn.Linear(32, 16)\n",
        "        self.layer_3 = nn.Linear(16, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_UXJLMFo6LtK"
      },
      "outputs": [],
      "source": [
        "input_dim = 2\n",
        "output_dim = 2\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VoVfJBiGT6zq"
      },
      "outputs": [],
      "source": [
        "def trainer(X_train, y_train):\n",
        "    \"\"\"For training the model\"\"\"\n",
        "    learning_rate = 1e-3\n",
        "    num_epochs = 30\n",
        "    batch_size = 32\n",
        "    loss_values = []\n",
        "\n",
        "    input_dim = 2\n",
        "    output_dim = 2\n",
        "\n",
        "    model = NeuralNetwork(input_dim, output_dim)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
        "\n",
        "    train_data = TensorDataset(X_train, y_train)\n",
        "    train_dataloader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for Xt,yt in train_dataloader:\n",
        "            # In the starting for everyt training data our gradient should be 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(Xt)  # do the prediction\n",
        "            loss = loss_fn(pred, yt)  # calculate loss\n",
        "            loss_values.append(loss.item())   # keep storing the loss\n",
        "            loss.backward()   # do backpropagation and compute the gradients of all the model parameters\n",
        "            optimizer.step()   # update the parameters\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Qe55TkT_U3xX"
      },
      "outputs": [],
      "source": [
        "def tester(X_test,y_test,model):\n",
        "    \"\"\"For testing the model\"\"\"\n",
        "    test_data = TensorDataset(X_test,y_test)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xt,yt in test_data:\n",
        "            outputs = model(Xt)\n",
        "\n",
        "            predicted = torch.argmax(nn.functional.softmax(outputs, dim=-1)).item()\n",
        "\n",
        "            if (predicted==yt):\n",
        "                correct+=1\n",
        "            total+=1\n",
        "            true_labels.append(yt.item())\n",
        "            predicted_labels.append(predicted)\n",
        "\n",
        "    confusions = confusion_matrix(true_labels, predicted_labels)\n",
        "    print(\"Confusion Matrix: \", confusions)\n",
        "\n",
        "    accuracy = correct/total\n",
        "    print(\"Accuracy: \" + str(accuracy))\n",
        "\n",
        "    print(\"F1 Score\",f1_score(predicted_labels, true_labels))\n",
        "    print(\"Precision\",precision_score(predicted_labels, true_labels))\n",
        "    print(\"Recall\",recall_score(predicted_labels, true_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bd68bvfobOUU"
      },
      "outputs": [],
      "source": [
        "def probability_distib_finder(review, ai_dict, human_dict,type):\n",
        "    notations= [['JJ','JJS','JJR'],['NN','NNS','NNP','NNPS'],['RB','RBR','RBS']]\n",
        "\n",
        "    ai_prob = 0\n",
        "    human_prob = 0\n",
        "    words = [tag[0] for tag in pos_tag(word_tokenize(review)) if tag[1] in notations[type]]\n",
        "\n",
        "    for word in words:\n",
        "        if word in list(ai_dict.keys()):\n",
        "            ai_prob += ai_dict[word]\n",
        "        if word in list(human_dict.keys()):\n",
        "            human_prob += human_dict[word]\n",
        "\n",
        "    return [ai_prob, human_prob]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RDTzD3fZaWDm"
      },
      "outputs": [],
      "source": [
        "def predictor(ai_iclr_files, ai_neur_files, human_iclr_files, human_neur_files,ai_dict, human_dict):\n",
        "    \"\"\"For prediction of a dataset\"\"\"\n",
        "    ai_iclr = list(json.load(open(ai_iclr_files)).values())\n",
        "    ai_neur = list(json.load(open(ai_neur_files)).values())\n",
        "    human_iclr = list(json.load(open(human_iclr_files)).values())\n",
        "    human_neur = list(json.load(open(human_neur_files)).values())\n",
        "\n",
        "    # Finding probability distributions\n",
        "    ai_train = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_iclr[:608]] + [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_neur[:576]]\n",
        "    human_train = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_iclr[:608] for a in review] + [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_neur[:576] for a in review]\n",
        "\n",
        "    ai_test_iclr = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_iclr[608:]]\n",
        "    ai_test_neur = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_neur[576:]]\n",
        "    human_test_iclr = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_iclr[608:] for a in review]\n",
        "    human_test_neur = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_neur[576:] for a in review]\n",
        "\n",
        "    X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "    y_train = torch.tensor([1 for i in range(len(ai_train))] + [0 for i in range(len(human_train))])\n",
        "\n",
        "    # Shuffle the train dataset\n",
        "    perm_indices = torch.randperm(len(X_train))\n",
        "    X_train = X_train[perm_indices]\n",
        "    y_train = y_train[perm_indices]\n",
        "\n",
        "    # Train the model\n",
        "    model = trainer(X_train, y_train)\n",
        "\n",
        "    X_test_iclr = torch.tensor(ai_test_iclr + human_test_iclr,dtype=torch.float32)\n",
        "    X_test_neur = torch.tensor(ai_test_neur + human_test_neur,dtype=torch.float32)\n",
        "    y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "    y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "    # Shuffle the test dataset\n",
        "    perm_indices = torch.randperm(len(X_test_iclr))\n",
        "    X_test_iclr = X_test_iclr[perm_indices]\n",
        "    y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "    perm_indices = torch.randperm(len(X_test_neur))\n",
        "    X_test_neur = X_test_neur[perm_indices]\n",
        "    y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "    print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "    tester(X_test_iclr,y_test_iclr,model)\n",
        "    print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "    tester(X_test_neur,y_test_neur,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oc7zX-IlUjD-"
      },
      "outputs": [],
      "source": [
        "def trainer_tester(ai_iclr_train, ai_neur_train,human_iclr_train, human_neur_train,ai_iclr_test, ai_neur_test,human_iclr_test, human_neur_test,ai_dict, human_dict):\n",
        "    \"\"\"For training and testing the model of separate training and testing data\"\"\"\n",
        "\n",
        "    # Training part\n",
        "    ai_iclr = list(json.load(open(ai_iclr_train)).values())\n",
        "    ai_neur = list(json.load(open(ai_neur_train)).values())\n",
        "    human_iclr = list(json.load(open(human_iclr_train)).values())\n",
        "    human_neur = list(json.load(open(human_neur_train)).values())\n",
        "\n",
        "    # Finding probability distributions\n",
        "    ai_train = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_iclr[:608]] + [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_neur[:576]]\n",
        "    human_train = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_iclr[:608] for a in review] + [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_neur[:576] for a in review]\n",
        "\n",
        "    X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "    y_train = torch.tensor([1 for i in range(len(ai_train))] + [0 for i in range(len(human_train))])\n",
        "\n",
        "    # Shuffle the train dataset\n",
        "    perm_indices = torch.randperm(len(X_train))\n",
        "    X_train = X_train[perm_indices]\n",
        "    y_train = y_train[perm_indices]\n",
        "\n",
        "    # Train the model\n",
        "    model = trainer(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Testing part\n",
        "    ai_iclr_test = list(json.load(open(ai_iclr_test)).values())\n",
        "    ai_neur_test = list(json.load(open(ai_neur_test)).values())\n",
        "    human_iclr_test = list(json.load(open(human_iclr_test)).values())\n",
        "    human_neur_test = list(json.load(open(human_neur_test)).values())\n",
        "\n",
        "    ai_test_iclr = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_iclr[608:]]\n",
        "    ai_test_neur = [probability_distib_finder(review, ai_dict, human_dict,0) for review in ai_neur[576:]]\n",
        "    human_test_iclr = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_iclr[608:] for a in review]\n",
        "    human_test_neur = [probability_distib_finder(a, ai_dict, human_dict,0) for review in human_neur[576:] for a in review]\n",
        "\n",
        "    X_test_iclr = torch.tensor(ai_test_iclr + human_test_iclr,dtype=torch.float32)\n",
        "    X_test_neur = torch.tensor(ai_test_neur + human_test_neur,dtype=torch.float32)\n",
        "    y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "    y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "    # Shuffle the test dataset\n",
        "    perm_indices = torch.randperm(len(X_test_iclr))\n",
        "    X_test_iclr = X_test_iclr[perm_indices]\n",
        "    y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "    perm_indices = torch.randperm(len(X_test_neur))\n",
        "    X_test_neur = X_test_neur[perm_indices]\n",
        "    y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "    print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "    tester(X_test_iclr,y_test_iclr,model)\n",
        "    print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "    tester(X_test_neur,y_test_neur,model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bltbgC1hDpfn"
      },
      "source": [
        "## Adjective Model :-\n",
        "Training the model by considering tokens to be adjective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HSOCT4cTq-v1"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_adj_dict.json\") as f:\n",
        "    ai_adj_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_adj_dict.json\") as f:\n",
        "    human_adj_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor(\"Dataset/ai_iclr.json\",\"Dataset/ai_neur.json\",\"Dataset/human_iclr.json\",\"Dataset/human_neur.json\",ai_adj_dict, human_adj_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57jeJMpeD1fB"
      },
      "source": [
        "## Noun Model:-\n",
        "Training the model by considering the tokens to be noun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bnBCaCQXriA7"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_noun_dict.json\") as f:\n",
        "    ai_noun_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_noun_dict.json\") as f:\n",
        "    human_noun_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor(\"Dataset/ai_iclr.json\",\"Dataset/ai_neur.json\",\"Dataset/human_iclr.json\",\"Dataset/human_neur.json\",ai_noun_dict, human_noun_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIysM3vMEckt"
      },
      "source": [
        "## Adverb Model:-\n",
        "Training the model by considering the tokens to be adverb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kJjYO72YEbcs"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_adverb_dict.json\") as f:\n",
        "    ai_adverb_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_adverb_dict.json\") as f:\n",
        "    human_adverb_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor(\"Dataset/ai_iclr.json\",\"Dataset/ai_neur.json\",\"Dataset/human_iclr.json\",\"Dataset/human_neur.json\",ai_adverb_dict, human_adverb_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GrjuD9lHbrm"
      },
      "source": [
        "## Synonym Attack (or Adjective Attack):-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5rxr9xwDZTob"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_adj_dict.json\") as f:\n",
        "    ai_adj_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_adj_dict.json\") as f:\n",
        "    human_adj_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_tester(\"Dataset/ai_iclr.json\",\"Dataset/ai_neur.json\",\"Dataset/human_iclr.json\",\"Dataset/human_neur.json\",\"Dataset/Attacked Dataset/Adjective Attack/ai_iclr.json\",\"Dataset/Attacked Dataset/Adjective Attack/ai_neur.json\",\"Dataset/Attacked Dataset/Adjective Attack/human_iclr.json\",\"Dataset/Attacked Dataset/Adjective Attack/human_neur.json\",ai_adj_dict, human_adj_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joXFhqZOHKqF"
      },
      "source": [
        "## Paraphrasing Attack:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8NX4fHaZW_D"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_adj_dict.json\") as f:\n",
        "    ai_adj_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_adj_dict.json\") as f:\n",
        "    human_adj_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_tester(\"Dataset/ai_iclr.json\",\"Dataset/ai_neur.json\",\"Dataset/human_iclr.json\",\"Dataset/human_neur.json\",\"Dataset/Attacked Dataset/Paraphrasing Attack/para_ai_iclr.json\",\"Dataset/Attacked Dataset/Paraphrasing Attack/para_ai_neur.json\",\"Dataset/Attacked Dataset/Paraphrasing Attack/para_human_iclr.json\",\"Dataset/Attacked Dataset/Paraphrasing Attack/para_human_neur.json\",ai_adj_dict, human_adj_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe4uT_B-Zkac"
      },
      "source": [
        "## Modified Paraphrasing Attack :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qg5dLEGQZmun"
      },
      "outputs": [],
      "source": [
        "with open(\"Dictionaries/ai_adj_dict.json\") as f:\n",
        "    ai_adj_dict = json.load(f)\n",
        "with open(\"Dictionaries/human_adj_dict.json\") as f:\n",
        "    human_adj_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hg284ArwZpzC"
      },
      "outputs": [],
      "source": [
        "ai_iclr = list(json.load(open(\"Dataset/ai_iclr.json\")).values())\n",
        "ai_neur = list(json.load(open(\"Dataset/ai_neur.json\")).values())\n",
        "human_iclr = list(json.load(open(\"Dataset/human_iclr.json\")).values())\n",
        "human_neur = list(json.load(open(\"Dataset/human_neur.json\")).values())\n",
        "\n",
        "ai_iclr_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Review/ai_iclr_modified.json\")).values())\n",
        "ai_neur_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Review/ai_neur_modified.json\")).values())\n",
        "human_iclr_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Review/human_iclr_modified.json\")).values())\n",
        "human_neur_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Review/human_neur_modified.json\")).values())\n",
        "\n",
        "ai_iclr_para_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Paraphrased/ai_iclr_para_modified.json\")).values())\n",
        "ai_neur_para_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Paraphrased/ai_neur_para_modified.json\")).values())\n",
        "human_iclr_para_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Paraphrased/human_iclr_para_modified.json\")).values())\n",
        "human_neur_para_modified = list(json.load(open(\"Dataset/Attacked Dataset/Modified Paraphrasing Attack/Modified Paraphrased/human_neur_para_modified.json\")).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5SAHHGAWp_Os"
      },
      "outputs": [],
      "source": [
        "# Finding probability distributions\n",
        "ai_train = [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr[:608]] + [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur[:576]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_modified[:608]] + [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_modified[:576]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_para_modified[:608]] + [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_para_modified[:576]]\n",
        "human_train = [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr[:608] for a in review] + [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur[:576] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_modified[:608] for a in review] + [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_modified[:576] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_para_modified[:608] for a in review] + [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_para_modified[:576] for a in review]\n",
        "\n",
        "X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "y_train = torch.tensor([1 for i in range(len(ai_train))] + [0 for i in range(len(human_train))])\n",
        "\n",
        "# Shuffle the train dataset\n",
        "perm_indices = torch.randperm(len(X_train))\n",
        "X_train = X_train[perm_indices]\n",
        "y_train = y_train[perm_indices]\n",
        "\n",
        "# Train the model\n",
        "model = trainer(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the Modified Paraphrased Dataset:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing only modified paraphrased part\n",
        "ai_test_iclr =    [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_para_modified[608:]]\n",
        "human_test_iclr =    [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_para_modified[608:] for a in review]\n",
        "\n",
        "ai_test_neur = [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_modified[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_para_modified[576:]]\n",
        "human_test_neur = [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur[576:] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_modified[576:] for a in review]  +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_para_modified[576:] for a in review]\n",
        "\n",
        "X_test_iclr = torch.tensor(ai_test_iclr + human_test_iclr,dtype=torch.float32)\n",
        "X_test_neur = torch.tensor(ai_test_neur + human_test_neur,dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the Modified Actual Review Dataset :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing only modified actual review\n",
        "ai_test_iclr =   [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_modified[608:]]\n",
        "human_test_iclr =  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_modified[608:] for a in review]\n",
        "\n",
        "ai_test_neur = [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_modified[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_para_modified[576:]]\n",
        "human_test_neur = [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur[576:] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_modified[576:] for a in review]  +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_para_modified[576:] for a in review]\n",
        "\n",
        "X_test_iclr = torch.tensor(ai_test_iclr + human_test_iclr,dtype=torch.float32)\n",
        "X_test_neur = torch.tensor(ai_test_neur + human_test_neur,dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing by combining all of them :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# By combining them all\n",
        "ai_test_iclr = [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr[608:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_modified[608:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_iclr_para_modified[608:]]\n",
        "human_test_iclr = [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr[608:] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_modified[608:] for a in review]  +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_iclr_para_modified[608:] for a in review]\n",
        "\n",
        "ai_test_neur = [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_modified[576:]] +  [probability_distib_finder(review, ai_adj_dict, human_adj_dict,0) for review in ai_neur_para_modified[576:]]\n",
        "human_test_neur = [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur[576:] for a in review] +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_modified[576:] for a in review]  +  [probability_distib_finder(a, ai_adj_dict, human_adj_dict,1) for review in human_neur_para_modified[576:] for a in review]\n",
        "\n",
        "X_test_iclr = torch.tensor(ai_test_iclr + human_test_iclr,dtype=torch.float32)\n",
        "X_test_neur = torch.tensor(ai_test_neur + human_test_neur,dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyZR2wZI0IGl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
