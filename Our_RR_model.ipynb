{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37sK-V9nuDY8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDeco5vAvfB2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzHWZfa42F3v"
      },
      "source": [
        "# Neural Network:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQTkfaHM2H8B"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layer_2 = nn.Linear(32, 16)\n",
        "        self.layer_3 = nn.Linear(16, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvVhheBqIK4X"
      },
      "outputs": [],
      "source": [
        "input_dim = 1\n",
        "hidden_dim=16\n",
        "output_dim = 2\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU(0.2)\n",
        "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ad7QvOc2cZi"
      },
      "outputs": [],
      "source": [
        "def trainer(X_train, y_train):\n",
        "    \"\"\"For training the model\"\"\"\n",
        "    learning_rate = 0.01\n",
        "    num_epochs = 20\n",
        "    batch_size = 32\n",
        "    loss_values = []\n",
        "\n",
        "    input_dim = 1\n",
        "    output_dim = 2\n",
        "\n",
        "    model = NeuralNetwork(input_dim, output_dim)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
        "\n",
        "    train_data = TensorDataset(X_train, y_train)\n",
        "    train_dataloader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for Xt,yt in train_dataloader:\n",
        "            # In the starting for everyt training data our gradient should be 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(Xt)  # do the prediction\n",
        "            loss = loss_fn(pred, yt)  # calculate loss\n",
        "            loss_values.append(loss.item())   # keep storing the loss\n",
        "            loss.backward()   # do backpropagation and compute the gradients of all the model parameters\n",
        "            optimizer.step()   # update the parameters\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EqrcscS2tHr"
      },
      "outputs": [],
      "source": [
        "def tester(X_test,y_test,model):\n",
        "    \"\"\"For testing the model\"\"\"\n",
        "    test_data = TensorDataset(X_test,y_test)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xt,yt in test_data:\n",
        "            outputs = model(Xt)\n",
        "\n",
        "            predicted = torch.argmax(nn.functional.softmax(outputs, dim=-1)).item()\n",
        "\n",
        "            if (predicted==yt):\n",
        "                correct+=1\n",
        "            total+=1\n",
        "            true_labels.append(yt.item())\n",
        "            predicted_labels.append(predicted)\n",
        "\n",
        "    confusions = confusion_matrix(true_labels, predicted_labels)\n",
        "    print(\"Confusion Matrix: \", confusions)\n",
        "\n",
        "    accuracy = correct/total\n",
        "    print(\"Accuracy: \" + str(accuracy))\n",
        "\n",
        "    print(\"F1 Score\",f1_score(predicted_labels, true_labels))\n",
        "    print(\"Precision\",precision_score(predicted_labels, true_labels))\n",
        "    print(\"Recall\",recall_score(predicted_labels, true_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGOGpwW82y_E"
      },
      "outputs": [],
      "source": [
        "def similarity_finder(embed1, embed2,isAI):\n",
        "  \"\"\"Function for finding similarities between two reviews using embeddings\"\"\"\n",
        "  similarities = []\n",
        "\n",
        "  if (isAI):   # whether embed1 is AI or not\n",
        "    for i in range(len(embed1)):\n",
        "      ind = list(embed1.keys())[i]\n",
        "      try:\n",
        "        similarities.append(cosine_similarity([embed1[ind]], [embed2[ind]]))\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  else:\n",
        "    for i in range(len(embed1)):\n",
        "      ind = list(embed1.keys())[i]\n",
        "      sim = []\n",
        "      try:\n",
        "        for j in range(len(embed1[ind])):\n",
        "            sim.append(cosine_similarity([embed1[ind][j]],[embed2[ind]]))\n",
        "        similarities.append(sim)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzEEkVx25XCd"
      },
      "outputs": [],
      "source": [
        "def predictor(ai_iclr_embed, ai_neur_embed, human_iclr_embed, human_neur_embed, gpt_iclr_embed, gpt_neur_embed):\n",
        "    # Loading the files\n",
        "    ai_iclr = json.load(open(ai_iclr_embed))\n",
        "    ai_neur = json.load(open(ai_neur_embed))\n",
        "    human_iclr = json.load(open(human_iclr_embed))\n",
        "    human_neur = json.load(open(human_neur_embed))\n",
        "    gpt_iclr = json.load(open(gpt_iclr_embed))\n",
        "    gpt_neur = json.load(open(gpt_neur_embed))\n",
        "\n",
        "    # Finding out the similarities\n",
        "    ai_iclr_sim = similarity_finder(ai_iclr, gpt_iclr,1)\n",
        "    ai_neur_sim = similarity_finder(ai_neur, gpt_neur,1)\n",
        "    human_iclr_sim = similarity_finder(human_iclr, gpt_iclr,0)\n",
        "    human_neur_sim = similarity_finder(human_neur, gpt_neur,0)\n",
        "\n",
        "    ai_train = [[a[0][0]] for a in ai_iclr_sim[:608]] + [[a[0][0]] for a in ai_neur_sim[:576]]\n",
        "    human_train = [[a[0][0]] for revw in human_iclr_sim[:608] for a in revw] + [[a[0][0]] for revw in human_neur_sim[:576] for a in revw]\n",
        "    X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "    y_train = torch.tensor([1 for i in ai_train] + [0 for i in human_train])\n",
        "\n",
        "    # Shuffle the train dataset\n",
        "    perm_indices = torch.randperm(len(X_train))\n",
        "    X_train = X_train[perm_indices]\n",
        "    y_train = y_train[perm_indices]\n",
        "\n",
        "    # Training the model\n",
        "    model = trainer(X_train,y_train)\n",
        "\n",
        "    human_test_iclr = [[a[0][0]] for revw in human_iclr_sim[608:] for a in revw]\n",
        "    X_test_iclr = torch.tensor([[a[0][0]] for a in ai_iclr_sim[608:]] + human_test_iclr, dtype=torch.float32)\n",
        "    y_test_iclr = torch.tensor([1 for i in ai_iclr_sim[608:]] + [0 for i in human_test_iclr])\n",
        "\n",
        "    human_test_neur = [[a[0][0]] for revw in human_neur_sim[576:] for a in revw]\n",
        "    X_test_neur = torch.tensor([[a[0][0]] for a in ai_neur_sim[576:]] + human_test_neur, dtype=torch.float32)\n",
        "    y_test_neur = torch.tensor([1 for i in ai_neur_sim[576:]] + [0 for i in human_test_neur])\n",
        "\n",
        "    print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "    tester(X_test_iclr,y_test_iclr,model)\n",
        "    print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "    tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgZWlovrFFXv"
      },
      "outputs": [],
      "source": [
        "def trainer_tester(ai_iclr_embed_train, ai_neur_embed_train, human_iclr_embed_train, human_neur_embed_train,ai_iclr_embed_test, ai_neur_embed_test, human_iclr_embed_test, human_neur_embed_test,gpt_iclr_embed, gpt_neur_embed):\n",
        "    # Training files\n",
        "    ai_iclr_train = json.load(open(ai_iclr_embed_train))\n",
        "    ai_neur_train = json.load(open(ai_neur_embed_train))\n",
        "    human_iclr_train = json.load(open(human_iclr_embed_train))\n",
        "    human_neur_train = json.load(open(human_neur_embed_train))\n",
        "\n",
        "    # Testing files\n",
        "    ai_iclr_test = json.load(open(ai_iclr_embed_test))\n",
        "    ai_neur_test = json.load(open(ai_neur_embed_test))\n",
        "    human_iclr_test = json.load(open(human_iclr_embed_test))\n",
        "    human_neur_test = json.load(open(human_neur_embed_test))\n",
        "    gpt_iclr = json.load(open(gpt_iclr_embed))\n",
        "    gpt_neur = json.load(open(gpt_neur_embed))\n",
        "\n",
        "     # Finding out the similarities\n",
        "    ai_iclr_sim = similarity_finder(ai_iclr_train, gpt_iclr,1)\n",
        "    ai_neur_sim = similarity_finder(ai_neur_train, gpt_neur,1)\n",
        "    human_iclr_sim = similarity_finder(human_iclr_train, gpt_iclr,0)\n",
        "    human_neur_sim = similarity_finder(human_neur_train, gpt_neur,0)\n",
        "\n",
        "    ai_iclr_sim_test = similarity_finder(ai_iclr_test, gpt_iclr,1)\n",
        "    ai_neur_sim_test = similarity_finder(ai_neur_test, gpt_neur,1)\n",
        "    human_iclr_sim_test = similarity_finder(human_iclr_test, gpt_iclr,1)\n",
        "    human_neur_sim_test = similarity_finder(human_neur_test, gpt_neur,1)\n",
        "\n",
        "    ai_train = [[a[0][0]] for a in ai_iclr_sim] + [[a[0][0]] for a in ai_neur_sim]\n",
        "    human_train = [[a[0][0]] for revw in human_iclr_sim for a in revw] + [[a[0][0]] for revw in human_neur_sim for a in revw]\n",
        "    X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "    y_train = torch.tensor([1 for i in ai_train] + [0 for i in human_train])\n",
        "\n",
        "    # Shuffle the train dataset\n",
        "    perm_indices = torch.randperm(len(X_train))\n",
        "    X_train = X_train[perm_indices]\n",
        "    y_train = y_train[perm_indices]\n",
        "\n",
        "    # Training the model\n",
        "    model = trainer(X_train,y_train)\n",
        "\n",
        "    human_test_iclr = [[a[0][0]] for a in human_iclr_sim_test]\n",
        "    X_test_iclr = torch.tensor([[a[0][0]] for a in ai_iclr_sim_test] + human_test_iclr, dtype=torch.float32)\n",
        "    y_test_iclr = torch.tensor([1 for i in ai_iclr_sim_test] + [0 for i in human_test_iclr])\n",
        "\n",
        "    # Shuffle the test dataset\n",
        "    perm_indices = torch.randperm(len(X_test_iclr))\n",
        "    X_test_iclr = X_test_iclr[perm_indices]\n",
        "    y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "    human_test_neur = [[a[0][0]] for a in human_neur_sim_test]\n",
        "    X_test_neur = torch.tensor([[a[0][0]] for a in ai_neur_sim_test] + human_test_neur, dtype=torch.float32)\n",
        "    y_test_neur = torch.tensor([1 for i in ai_neur_sim_test] + [0 for i in human_test_neur])\n",
        "\n",
        "    # Shuffle the test dataset\n",
        "    perm_indices = torch.randperm(len(X_test_neur))\n",
        "    X_test_neur = X_test_neur[perm_indices]\n",
        "    y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "    print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "    tester(X_test_iclr,y_test_iclr,model)\n",
        "    print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "    tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyglUsz7IQda"
      },
      "source": [
        "## Predicting Actual Reviews:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor(f\"Embeddings/ai_iclr_embed\",f\"Embeddings/ai_neur_embed\",f\"Embeddings/human_iclr_embed\",f\"Embeddings/human_neur_embed\",f\"Embeddings/Regenerated Embeddings/gpt-4/gpt_iclr_embed\",f\"Embeddings/Regenerated Embeddings/gpt-4/gpt_neur_embed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li5tydCNI8ad"
      },
      "source": [
        "## Synonym Attack (or Adjective Attack:-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_path = \"Embeddings/\"\n",
        "embed_path1 = \"Embeddings/Attacked Embeddings/Paraphrasing Attack/\"\n",
        "trainer_tester(f\"{embed_path}ai_iclr_embed\",f\"{embed_path}ai_neur_embed\",f\"{embed_path}human_iclr_embed\",f\"{embed_path}human_neur_embed\",f\"{embed_path1}ai_iclr_para_attack_embed_test\",f\"{embed_path1}ai_neur_para_attack_embed_test\",f\"{embed_path1}human_iclr_para_attack_embed_test\",f\"{embed_path1}human_neur_para_attack_embed_test\",f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_iclr_embed\",f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_neur_embed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0J896t1Cskf"
      },
      "source": [
        "## Paraphrasing Attack:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_path = \"Embeddings/\"\n",
        "embed_path1 = \"Embeddings/Attacked Embeddings/Paraphrasing Attack/\"\n",
        "trainer_tester(f\"{embed_path}ai_iclr_embed\",f\"{embed_path}ai_neur_embed\",f\"{embed_path}human_iclr_embed\",f\"{embed_path}human_neur_embed\",f\"{embed_path1}ai_iclr_para_attack_embed_test\",f\"{embed_path1}ai_neur_para_attack_embed_test\",f\"{embed_path1}human_iclr_para_attack_embed_test\",f\"{embed_path1}human_neur_para_attack_embed_test\",f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_iclr_embed\",f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_neur_embed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgGs7jbQMRTV"
      },
      "source": [
        "## Modified Paraphrasing Attack:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhuzR8hENB-x"
      },
      "outputs": [],
      "source": [
        "# Training files\n",
        "embed_path = \"Embeddings/\"\n",
        "ai_iclr = json.load(open(f\"{embed_path}ai_iclr_embed\"))\n",
        "ai_neur = json.load(open(f\"{embed_path}ai_neur_embed\"))\n",
        "human_iclr = json.load(open(f\"{embed_path}human_iclr_embed\"))\n",
        "human_neur = json.load(open(f\"{embed_path}human_neur_embed\"))\n",
        "\n",
        "embed_path1 = \"Embeddings/Attacked Embeddings/Modified Paraphrasing Attack/Modified Paraphrased/\"\n",
        "ai_iclr_modified_para = pickle.load(open(f\"{embed_path1}ai_iclr_modified_embed_para.pkl\",\"rb\"))\n",
        "ai_neur_modified_para = pickle.load(open(f\"{embed_path1}ai_neur_modified_embed_para.pkl\",\"rb\"))\n",
        "human_iclr_modified_para = pickle.load(open(f\"{embed_path1}human_iclr_modified_embed_para.pkl\",\"rb\"))\n",
        "human_neur_modified_para = pickle.load(open(f\"{embed_path1}human_neur_modified_embed_para.pkl\",\"rb\"))\n",
        "\n",
        "embed_path2 = \"Embeddings/Attacked Embeddings/Modified Paraphrasing Attack/Modified Reviews/\"\n",
        "ai_iclr_modified = pickle.load(open(f\"{embed_path2}ai_iclr_review_modified_embed.pkl\",\"rb\"))\n",
        "ai_neur_modified = pickle.load(open(f\"{embed_path2}ai_neur_review_modified_embed.pkl\",\"rb\"))\n",
        "human_iclr_modified = pickle.load(open(f\"{embed_path2}human_iclr_review_modified_embed.pkl\",\"rb\"))\n",
        "human_neur_modified = pickle.load(open(f\"{embed_path2}human_neur_review_modified_embed.pkl\",\"rb\"))\n",
        "\n",
        "gpt_iclr = json.load(open(f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_iclr_embed\"))\n",
        "gpt_neur = json.load(open(f\"{embed_path}Regenerated Embeddings/gpt-4/gpt_neur_embed\"))\n",
        "\n",
        "# Testing files\n",
        "ai_iclr_modified_para_test = pickle.load(open(f\"{embed_path1}ai_iclr_modified_para_test.pkl\",\"rb\"))\n",
        "ai_neur_modified_para_test = pickle.load(open(f\"{embed_path1}ai_neur_modified_para_test.pkl\",\"rb\"))\n",
        "human_iclr_modified_para_test = pickle.load(open(f\"{embed_path1}human_iclr_modified_para_test.pkl\",\"rb\"))\n",
        "human_neur_modified_para_test = pickle.load(open(f\"{embed_path1}human_neur_modified_para_test.pkl\",\"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S4bidIXX2F8"
      },
      "outputs": [],
      "source": [
        "# Finding out the similarities\n",
        "ai_iclr_sim = similarity_finder(ai_iclr, gpt_iclr,1)\n",
        "ai_neur_sim = similarity_finder(ai_neur, gpt_neur,1)\n",
        "human_iclr_sim = similarity_finder(human_iclr, gpt_iclr,0)\n",
        "human_neur_sim = similarity_finder(human_neur, gpt_neur,0)\n",
        "\n",
        "ai_iclr_sim_modified_para = similarity_finder(ai_iclr_modified_para, gpt_iclr,1)\n",
        "ai_neur_sim_modified_para = similarity_finder(ai_neur_modified_para, gpt_neur,1)\n",
        "human_iclr_sim_modified_para = similarity_finder(human_iclr_modified_para, gpt_iclr,0)\n",
        "human_neur_sim_modified_para = similarity_finder(human_neur_modified_para, gpt_neur,0)\n",
        "\n",
        "ai_iclr_sim_modified = similarity_finder(ai_iclr_modified, gpt_iclr,1)\n",
        "ai_neur_sim_modified = similarity_finder(ai_neur_modified, gpt_neur,1)\n",
        "human_iclr_sim_modified = similarity_finder(human_iclr_modified, gpt_iclr,0)\n",
        "human_neur_sim_modified = similarity_finder(human_neur_modified, gpt_neur,0)\n",
        "\n",
        "ai_iclr_sim_modified_para_test = similarity_finder(ai_iclr_modified_para_test, gpt_iclr,1)\n",
        "ai_neur_sim_modified_para_test = similarity_finder(ai_neur_modified_para_test, gpt_neur,1)\n",
        "human_iclr_sim_modified_para_test = similarity_finder(human_iclr_modified_para_test, gpt_iclr,0)\n",
        "human_neur_sim_modified_para_test = similarity_finder(human_neur_modified_para_test, gpt_neur,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CykeQgWrgHnw",
        "outputId": "c032559d-7ada-458d-ab0e-3a372e393af1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-4daf88d32d4d>:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
            "<ipython-input-71-4daf88d32d4d>:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "ai_train = [[a[0][0]] for a in ai_iclr_sim[:608]] + [[a[0][0]] for a in ai_neur_sim[:576]] + [[a[0][0]] for a in ai_iclr_sim_modified_para] + [[a[0][0]] for a in ai_neur_sim_modified_para] + [[a[0][0]] for a in ai_iclr_sim_modified[:608]] + [[a[0][0]] for a in ai_neur_sim_modified[:576]]\n",
        "human_train = [[a[0][0]] for revw in human_iclr_sim[:608]] + [[a[0][0]] for revw in human_neur_sim[:576]] + [[a[0][0]] for revw in human_iclr_sim_modified_para for a in revw] + [[a[0][0]] for revw in human_neur_sim_modified_para for a in revw] + [[a[0][0]] for a in human_iclr_sim_modified[:608]] + [[a[0][0]] for a in human_neur_sim_modified[:576]]\n",
        "\n",
        "X_train = torch.tensor(ai_train + human_train,dtype=torch.float32)\n",
        "y_train = torch.tensor([1 for i in ai_train] + [0 for i in human_train])\n",
        "\n",
        "# Shuffle the train dataset\n",
        "perm_indices = torch.randperm(len(X_train))\n",
        "X_train = X_train[perm_indices]\n",
        "y_train = y_train[perm_indices]\n",
        "\n",
        "# Training the model\n",
        "model = trainer(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the Modified Paraphrased Dataset:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing the paraphrased model all alone\n",
        "ai_test_iclr =  [[a[0][0]] for a in ai_iclr_sim_modified_para_test]\n",
        "human_test_iclr =  [[a[0][0]] for revw in human_iclr_sim_modified_para_test for a in revw]\n",
        "X_test_iclr = torch.tensor(ai_test_iclr+ human_test_iclr, dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "ai_test_neur =  [[a[0][0]] for a in ai_neur_sim_modified_para_test]\n",
        "human_test_neur =  [[a[0][0]] for revw in human_neur_sim_modified_para_test for a in revw]\n",
        "X_test_neur = torch.tensor(ai_test_neur+ human_test_neur, dtype=torch.float32)\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the Modified Actual Review Dataset :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing by only on the modified actual review\n",
        "ai_test_iclr = [[a[0][0]] for a in ai_iclr_sim_modified[608:]]\n",
        "human_test_iclr = [[a[0][0]] for a in human_iclr_sim_modified[608:]]\n",
        "X_test_iclr = torch.tensor(ai_test_iclr+ human_test_iclr, dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "ai_test_neur =  [[a[0][0]] for a in ai_neur_sim_modified[576:]]\n",
        "human_test_neur = [[a[0][0]] for a in human_neur_sim_modified[576:]]\n",
        "X_test_neur = torch.tensor(ai_test_neur+ human_test_neur, dtype=torch.float32)\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing by combining all of them :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing by combining them all\n",
        "ai_test_iclr = [[a[0][0]] for a in ai_iclr_sim[608:]] + [[a[0][0]] for a in ai_iclr_sim_modified_para_test]  + [[a[0][0]] for a in ai_iclr_sim_modified[608:]]\n",
        "human_test_iclr = [[a[0][0]] for revw in human_iclr_sim[608:]]  + [[a[0][0]] for revw in human_iclr_sim_modified_para_test for a in revw] + [[a[0][0]] for a in human_iclr_sim_modified[608:]]\n",
        "X_test_iclr = torch.tensor(ai_test_iclr+ human_test_iclr, dtype=torch.float32)\n",
        "y_test_iclr = torch.tensor([1 for i in range(len(ai_test_iclr))] + [0 for i in range(len(human_test_iclr))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_iclr))\n",
        "X_test_iclr = X_test_iclr[perm_indices]\n",
        "y_test_iclr = y_test_iclr[perm_indices]\n",
        "\n",
        "ai_test_neur = [[a[0][0]] for a in ai_neur_sim[576:]] + [[a[0][0]] for a in ai_neur_sim_modified_para_test]  + [[a[0][0]] for a in ai_neur_sim_modified[576:]]\n",
        "human_test_neur = [[a[0][0]] for revw in human_neur_sim[576:]]  + [[a[0][0]] for revw in human_neur_sim_modified_para_test for a in revw] + [[a[0][0]] for a in human_neur_sim_modified[576:]]\n",
        "X_test_neur = torch.tensor(ai_test_neur+ human_test_neur, dtype=torch.float32)\n",
        "y_test_neur = torch.tensor([1 for i in range(len(ai_test_neur))] + [0 for i in range(len(human_test_neur))])\n",
        "\n",
        "# Shuffle the test dataset\n",
        "perm_indices = torch.randperm(len(X_test_neur))\n",
        "X_test_neur = X_test_neur[perm_indices]\n",
        "y_test_neur = y_test_neur[perm_indices]\n",
        "\n",
        "print(\"++++++++++++++++++ ICLR ++++++++++++++++++\")\n",
        "tester(X_test_iclr,y_test_iclr,model)\n",
        "print(\"\\n++++++++++++++++++ NeurIPS ++++++++++++++++++\")\n",
        "tester(X_test_neur,y_test_neur,model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
